{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# AP3 - Pattern Recognition\n",
    "Implementation of a decision tree for classifying a database with categorical attributes.\n",
    "\n",
    "> Name: Jonas Carvalho Fortes\n",
    "\n",
    "> Mat: 494513"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (876, 4)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from scipy.io import loadmat\n",
    "\n",
    "dataset = loadmat('data/Dataset.mat')\n",
    "dataset = pd.DataFrame(dataset['Dataset'])\n",
    "print(f'Dataset shape: {dataset.shape}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset:\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>871</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>872</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>873</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>874</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>875</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>876 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0  1  2  3\n",
       "0    1  0  0  1\n",
       "1    0  0  0  1\n",
       "2    0  0  0  0\n",
       "3    0  0  0  0\n",
       "4    0  0  0  1\n",
       "..  .. .. .. ..\n",
       "871  1  1  0  1\n",
       "872  1  1  0  1\n",
       "873  1  1  0  1\n",
       "874  1  0  1  1\n",
       "875  1  0  0  1\n",
       "\n",
       "[876 rows x 4 columns]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "print('Dataset:')\n",
    "dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Helper functions and classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "def entropy(labels):\n",
    "    \"\"\"\n",
    "    Calcula a entropia de um conjunto de rótulos.\n",
    "    \n",
    "    Args:\n",
    "        labels (np.ndarray): Array contendo os rótulos dos dados (0 ou 1).\n",
    "    \n",
    "    Returns:\n",
    "        float: Entropia do conjunto de rótulos.\n",
    "    \"\"\"\n",
    "    # Calcula a frequência de cada classe\n",
    "    values, counts = np.unique(labels, return_counts=True)\n",
    "    \n",
    "    # Calcula a probabilidade de cada classe\n",
    "    probabilities = counts / len(labels)\n",
    "    \n",
    "    # Calcula a entropia usando a fórmula da entropia\n",
    "    entropy_value = -np.sum(probabilities * np.log2(probabilities + EPSILON))\n",
    "    \n",
    "    return entropy_value\n",
    "\n",
    "def information_gain(original_labels, left_labels, right_labels):\n",
    "    \"\"\"\n",
    "    Calcula o ganho de informação de uma divisão dos dados.\n",
    "    \n",
    "    Args:\n",
    "        original_labels (np.ndarray): Rótulos antes da divisão.\n",
    "        left_labels (np.ndarray): Rótulos do subconjunto à esquerda.\n",
    "        right_labels (np.ndarray): Rótulos do subconjunto à direita.\n",
    "    \n",
    "    Returns:\n",
    "        float: Ganho de informação da divisão.\n",
    "    \"\"\"\n",
    "    # Entropia antes da divisão\n",
    "    original_entropy = entropy(original_labels)\n",
    "    \n",
    "    # Calcula a entropia ponderada após a divisão\n",
    "    total_len = len(original_labels)\n",
    "    left_prob = len(left_labels) / total_len\n",
    "    right_prob = len(right_labels) / total_len\n",
    "    \n",
    "    # Entropia ponderada após a divisão\n",
    "    weighted_entropy = (left_prob * entropy(left_labels)) + (right_prob * entropy(right_labels))\n",
    "    \n",
    "    # Ganho de informação\n",
    "    gain = original_entropy - weighted_entropy\n",
    "    \n",
    "    return gain\n",
    "\n",
    "def get_majority_class(labels):\n",
    "    \"\"\"\n",
    "    Obtém a classe majoritária de um conjunto de rótulos.\n",
    "    \n",
    "    Args:\n",
    "        labels (np.ndarray): Array contendo os rótulos dos dados (0 ou 1).\n",
    "    \n",
    "    Returns:\n",
    "        int: A classe majoritária.\n",
    "    \"\"\"\n",
    "    # Conta a frequência de cada classe\n",
    "    values, counts = np.unique(labels, return_counts=True)\n",
    "    \n",
    "    # Retorna a classe com a maior frequência\n",
    "    majority_class = values[np.argmax(counts)]\n",
    "    \n",
    "    return majority_class\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "\n",
    "# Menor valor de entropia possível que não seja zero (para evitar divisão por zero)\n",
    "EPSILON = np.finfo('float32').eps\n",
    "\n",
    "class Node:\n",
    "    \n",
    "    def __init__(self, left, right, data=None, feature_idx=None, \n",
    "                 feature_name=None, criterion_value=None,\n",
    "                 _result=None, class_name=None):\n",
    "        \n",
    "        self.left: Node = left\n",
    "        self.right: Node = right\n",
    "\n",
    "        self.data = data\n",
    "        self.feature_idx: int = feature_idx\n",
    "        self.feature_name: str = feature_name\n",
    "        self.criterion_value: float = criterion_value\n",
    "        self.n_sample: int = len(data) if data is not None else 0\n",
    "        self._result = _result\n",
    "        self.class_name: str = class_name\n",
    "\n",
    "    def predict(self, x):\n",
    "        if x[self.feature_idx] == 0:\n",
    "            return self.left.predict(x)\n",
    "        else:  # Aqui x[self.feature_idx] deve ser 1\n",
    "            return self.right.predict(x)\n",
    "\n",
    "\n",
    "class LeafNode(Node):\n",
    "    def __init__(self, data, criterion_value, _result, class_name):\n",
    "        super().__init__(None, None, data=data, \n",
    "                         criterion_value=criterion_value, \n",
    "                         _result=_result, class_name=class_name)\n",
    "\n",
    "    def predict(self, X=None):\n",
    "        return self._result\n",
    "    \n",
    "    \n",
    "class DecisionTree: \n",
    "    \n",
    "    def __init__(self, feature_names=[], class_names=[]):\n",
    "        self.root: Node = Node(None, None)\n",
    "        self.feature_names = feature_names\n",
    "        self.class_names = class_names\n",
    "    \n",
    "    def fit(self, X: np.ndarray, y: np.ndarray):\n",
    "         # Cria um array de dados que inclui atributos e rótulos\n",
    "        data = np.hstack((X, y.reshape(-1, 1)))\n",
    "        # Chama o método grow para construir a árvore\n",
    "        self.root = self._grow(data)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        return self.root.predict(X)\n",
    "\n",
    "    def _split_data(self, feature_data, labels):\n",
    "        \"\"\"\n",
    "        Divide os dados com base nos valores categóricos (0 ou 1) do atributo.\n",
    "        \"\"\"\n",
    "        # Dividindo à esquerda (valor 0)\n",
    "        left_indices = feature_data == 0\n",
    "        left_labels = labels[left_indices]\n",
    "\n",
    "        # Dividindo à direita (valor 1)\n",
    "        right_indices = feature_data == 1\n",
    "        right_labels = labels[right_indices]\n",
    "\n",
    "        return (left_labels, right_labels)\n",
    "    \n",
    "    def _best_split(self, feature_data, labels):\n",
    "        \"\"\"\n",
    "        Avalia a entropia resultante da divisão dos dados para um determinado atributo categórico.\n",
    "        \"\"\"\n",
    "        # Dividindo os dados com base no valor binário do atributo (0 ou 1)\n",
    "        left_labels, right_labels = self._split_data(feature_data, labels)\n",
    "\n",
    "        # Calcula a entropia da divisão\n",
    "        cost_value = entropy(left_labels, right_labels)\n",
    "        \n",
    "        return cost_value\n",
    "    \n",
    "    def _best_feature(self, data, feature_idxs):\n",
    "        \"\"\"\n",
    "        Identifica o melhor atributo binário para dividir os dados.\n",
    "        \"\"\"\n",
    "        max_gain = -np.inf\n",
    "        selected_feature = None\n",
    "\n",
    "        for feature_idx in feature_idxs:\n",
    "            # Obtém os dados do atributo\n",
    "            feature_data = data[:, feature_idx]\n",
    "            labels = data[:, -1]\n",
    "            \n",
    "            # Avalia o ganho de informação para o atributo atual\n",
    "            left_labels, right_labels = self._split_data(feature_data, labels)\n",
    "            gain = information_gain(labels, left_labels, right_labels)\n",
    "\n",
    "            if gain > max_gain:\n",
    "                max_gain = gain\n",
    "                selected_feature = feature_idx\n",
    "        \n",
    "        return selected_feature, max_gain\n",
    "    \n",
    "    def _grow(self, data, used_features=None):\n",
    "        \"\"\"\n",
    "        Constrói recursivamente a árvore de decisão.\n",
    "        \"\"\"\n",
    "        if used_features is None:\n",
    "            used_features = set()\n",
    "\n",
    "        compute_criterion_value = entropy\n",
    "        get_result = get_majority_class\n",
    "\n",
    "        y = data[:, -1]\n",
    "        criterion_value = compute_criterion_value(y)\n",
    "        result = get_result(y)\n",
    "\n",
    "        class_name = self.class_names[result] if self.class_names else f\"{result:.4f}\"\n",
    "\n",
    "        # Critério de parada: parar se a entropia for zero (dados puros) ou se todos os atributos já tiverem sido usados\n",
    "        if criterion_value < EPSILON or len(used_features) >= 3:\n",
    "            return LeafNode(data, criterion_value=criterion_value, \n",
    "                            _result=result, class_name=class_name)\n",
    "\n",
    "        # Seleciona o melhor atributo para divisão\n",
    "        feature_idxs = [i for i in np.arange(data.shape[-1] - 1) if i not in used_features]\n",
    "        selected_feature, _ = self._best_feature(data, feature_idxs)\n",
    "\n",
    "        if selected_feature is None:\n",
    "            return LeafNode(data, criterion_value=criterion_value, \n",
    "                            _result=result, class_name=class_name)\n",
    "\n",
    "        used_features.add(selected_feature)\n",
    "\n",
    "        # Divide os dados com base no atributo selecionado\n",
    "        left_data = data[data[:, selected_feature] == 0]\n",
    "        right_data = data[data[:, selected_feature] == 1]\n",
    "\n",
    "        # Cria os nós filhos recursivamente\n",
    "        left_node = self._grow(left_data, used_features=used_features)\n",
    "        right_node = self._grow(right_data, used_features=used_features)\n",
    "\n",
    "        return Node(left_node, \n",
    "                    right_node,\n",
    "                    data, \n",
    "                    selected_feature, \n",
    "                    feature_name=self.feature_names[selected_feature] if any(self.feature_names) else \"NA\",\n",
    "                    criterion_value=criterion_value,\n",
    "                    _result=result, class_name=class_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separando atributos e rótulos\n",
    "X = dataset.iloc[:, :-1].values  # Atributos (todas as colunas exceto a última)\n",
    "y = dataset.iloc[:, -1].values   # Rótulo (última coluna)\n",
    "\n",
    "# Nomes dos atributos e classes\n",
    "feature_names = [\"Empregado\", \"Devedor\", \"Salário acima de 5SM\"]\n",
    "class_names = [\"não\", \"sim\"]\n",
    "\n",
    "# Criando e treinando a árvore de decisão\n",
    "tree = DecisionTree(feature_names=feature_names, class_names=class_names)\n",
    "tree.fit(X, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Previsões: ['sim', 'sim', 'não', 'sim', 'sim']\n"
     ]
    }
   ],
   "source": [
    "# Exemplo de previsão\n",
    "test_data = np.array([\n",
    "    [1, 0, 1],  # empregado: sim, devedor: não, salário acima de 5SM: sim\n",
    "    [0, 1, 0],  # empregado: não, devedor: sim, salário acima de 5SM: não (estranho ser classe 'sim')\n",
    "    [0, 0, 0],  # empregado: não, devedor: não, salário acima de 5SM: não\n",
    "    [1, 1, 1],  # empregado: sim, devedor: sim, salário acima de 5SM: sim\n",
    "    [1, 1, 0],  # empregado: sim, devedor: sim, salário acima de 5SM: não\n",
    "])\n",
    "\n",
    "# Prevendo com a árvore treinada\n",
    "predictions = [tree.predict(x) for x in test_data]\n",
    "print(\"Previsões:\", [class_names[pred] for pred in predictions])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "decision-tree",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
